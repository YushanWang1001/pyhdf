# $Id: INSTALL,v 1.5 2008-06-30 02:41:44 gosselin_a Exp $
# $Log: not supported by cvs2svn $
# Revision 1.4  2005/07/17 03:59:41  gosselin_a
# Fixed typo in header line.
#
# Revision 1.3  2005/07/14 01:36:41  gosselin_a
# pyhdf-0.7-3
# Ported to HDF4.2r1.
# Support for SZIP compression on SDS datasets.
# All classes are now 'new-style' classes, deriving from 'object'.
# Update documentation.
#
# Revision 1.2  2004/08/02 15:16:38  gosselin
# pyhdf 0.6-1
#
# Revision 1.1  2004/08/02 14:45:56  gosselin
# Initial revision
#

Installing the pyhdf python package.

pyhdf has been successfully installed under python 2.2 and above on
the following platforms:
  -Linux, kernel 2.4.19 and above
  -Tru64 4.0.f and above
  -Solaris 8
  -AIX 4

Please inform the maintainer (rkern@enthought.com) of any
successfull installation on a different platform, and of
problems encountered.

To install, follow these steps.

1-Install the HDF4 library. Source code is available at:
  http://hdf.ncsa.uiuc.edu/hdf4.html. Binary packages
  are available for most popular environments.
  Release 4.2r1 must be installed for pyhdf-0.7-3 to work.

  HDF4.2 in turn requires some libraries : libjpeg, libz, and libsz
  if the SZIP compression method is to be used.

2-Install the python NumPy package. Source code is
  available at: http://numpy.scipy.org/. Binary packages
  are available for most popular environments.
  Note that previous releases of pyhdf used the Numeric
  package rather than NumPy.

3-Uncompress and untar the pyhdf tar ball, then cd to the
  pyhdf-xxx directory just created.

4-If your HDF4 libraries or include files reside in directories
  that are not searched by default on your system,
  the installation script will complain about missing files.
  In that case, edit the `setup.py' file and locate the 
  lines reading:

    #include_dirs=["non standard path where hdf includes live"],
    #library_dirs=["non standard path where libs live"],

  Remove the pound sign to uncomment the line(s) to edit, and enter 
  the required paths in quotes between the square brackets. For ex.,
  if at your site HDF has been installed in directory
  "/usr/local/hdf-4.2r1", enter:

    include_dirs = ["/usr/local/hdf-4.2r1/include"]
    library_dirs = ["/usr/local/hdf-4.2r1/lib"],


  External libraries

  HDF4.2 no longer provides its own copies of the jpeg and z libraries.
  Those must be installed separately (on Linux, they should be part of
  any standard distribution). 

  The sz library (versions 2.0 or higher) must be installed if the SZIP 
  compression method is to be used with SDsetcompress(). HDF v4.2 must also 
  have been compiled with SZIP support. Precompiled HDF packages usually
  lack this feature, as in Fedora linux distributions. Getting
  an SZIP enabled HDF library may require compiling the library from source
  with the "--with-szlib" configuration option.
  Note that you *must* install SZIP in a separate step. For more details,
  see NCSA hdf site at : http://hdf.ncsa.uiuc.edu/doc_resource/SZIP/ ;
  source code and precompiled binaries are available at :
  ftp://ftp.hdfgroup.org/lib-external/szip/ . 

  In case your HDF library was compiled without SZIP support, or you cannot
  abide by the szip licensing terms, set the following inside file 
  'setup.py' (see comments inside this file) :

    extra_compile_args = ["-DNOSZIP"]
    libraries = ["mfhdf", "df", "jpeg", "z"]

  If you get error messages related to the SDgetcompress() / SDsetcompress()
  functions, eg.: "undefined symbol: SDgetcompress" (this seems to affect
  users of Debian based distros), try also setting the NOCOMPRESS macro :

    extra_compile_args = ["-DNOSZIP", "-DNOCOMPRESS"]

  With NOCOMPRESS set, SDgetcompress() and SDsetcompress() will be transformed
  into no-ops which will immediately raise an exception, and will not be resolved
  against the HDF library symbols. This may help you work with an HDF library
  earlier than v4.2.


  Swig-generated interface files

    Interface files 'hdfext.py' and 'hdfext_wrap.c' (located under the
    'pyhdf/' subdirectory) have been generated using the 'swig' tool.
    Those two files should be usable as is on most environments.
    It could happen however that, for a reason related to your environment,
    your C compiler does not accept the '.c' file and provokes a compilation
    error. If this is so, the interface files will need to be regenerated.
    For this you will first need to have the swig tool installed
    (see: http://www.swig.org). Then execute :

      # cd pyhdf
      # swig -python hdfext.i

    swig should silently regenerate the two interface files, and the install should now
    proceed correctly.


  TRU64 note
    The HDF installation creates its libraries as archive (.a) files,
    not shareable (.so) ones. On TRU64, the linker by default first looks
    for shareable libraries in every directory, then in a second round
    for archive files. This means that if there is a libjpeg.so somewhere 
    on the standard linker search paths, it will be found first, even if 
    the HDF libjpeg.a file exists in the directory pointed by "library_dirs". 
    To solve the problem, edit the line:
   
      #extra_link_args=["extra stuff passed to the linker"],

    changing it to:

      extra_link_args = ["-oldstyle_liblookup"],

    This will tell the linker to look for .so then for .a files in each visited
    directory.


5-As root, execute the command:

      # python setup.py install

    As a precaution, you may want to first wipe out any previus pyhdf 
    installation, if any :

      # rm -rf <python-stdlib-path>/site-packages/pyhdf

    where <python-stdlib-path> stands for the python standard library path
    (on linux: /usr/lib/pythonx.x).

   Warning messages about the implicit declaration of some functions can be produced.
   Those are due to the way the swig tool generates the C code, and can be safely ignored.

6- Before experimenting with pyhdf, exit root privileges and leave the installation directory
   (the one where you untarred the product). Failing to do so may cause all sorts
   of mysterious problems.

7- As a first test, run the 'hdfstruct.py' script (found under directory 'examples/hdfstruct')
   on one of your HDF4 files. The script should display the file structure. This is
   a handy tool to have around when you want to explore the contents of any HDF4 file.

Enjoy!
